{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3250631f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshuser/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pathlib\n",
    "from typing import Dict, List\n",
    "import trlx\n",
    "from trlx.data.default_configs import TRLConfig, default_ppo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10808d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_config = default_ppo_config().to_dict()\n",
    "default_config['train']['total_steps'] = 10\n",
    "default_config['train']['tracker'] = 'tensorboard'\n",
    "default_config['method']['chunk_size'] = 2\n",
    "\n",
    "config = TRLConfig.update(default_config, {})\n",
    "\n",
    "config.model.model_path = 'lvwerra/gpt2-imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2fe0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/sshuser/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    }
   ],
   "source": [
    "def reward_fn(samples: List[str], **kwargs) -> List[float]:\n",
    "    sentiments = list(map(get_positive_score, sentiment_fn(samples)))\n",
    "    return sentiments\n",
    "    \n",
    "def get_positive_score(scores):\n",
    "    \"Extract value associated with a positive sentiment from pipeline's output\"\n",
    "    return dict(map(lambda x: tuple(x.values()), scores))[\"POSITIVE\"]\n",
    "\n",
    "sentiment_fn = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    \"lvwerra/distilbert-imdb\",\n",
    "    top_k=2,\n",
    "    truncation=True,\n",
    "    batch_size=256,\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "imdb = load_dataset(\"imdb\", split=\"train+test\")\n",
    "prompts = [\" \".join(review.split()[:4]) for review in imdb[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ebb474-6bcf-4e22-a856-a1efa393a4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trlx.utils.loading import get_pipeline, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb54470f-d40e-434f-9f2e-aa89ae700302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sshuser/.local/lib/python3.10/site-packages/accelerate/accelerator.py:353: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "[RANK 0] Initializing model: lvwerra/gpt2-imdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"method\": {\n",
      "        \"name\": \"PPOConfig\",\n",
      "        \"ppo_epochs\": 4,\n",
      "        \"num_rollouts\": 128,\n",
      "        \"chunk_size\": 2,\n",
      "        \"init_kl_coef\": 0.05,\n",
      "        \"target\": 6,\n",
      "        \"horizon\": 10000,\n",
      "        \"gamma\": 1,\n",
      "        \"lam\": 0.95,\n",
      "        \"cliprange\": 0.2,\n",
      "        \"cliprange_value\": 0.2,\n",
      "        \"vf_coef\": 1,\n",
      "        \"scale_reward\": \"ignored\",\n",
      "        \"ref_mean\": null,\n",
      "        \"ref_std\": null,\n",
      "        \"cliprange_reward\": 10,\n",
      "        \"gen_kwargs\": {\n",
      "            \"max_new_tokens\": 40,\n",
      "            \"top_k\": 0,\n",
      "            \"top_p\": 1.0,\n",
      "            \"do_sample\": true\n",
      "        },\n",
      "        \"gen_experience_kwargs\": null\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"model_path\": \"lvwerra/gpt2-imdb\",\n",
      "        \"model_arch_type\": \"causal\",\n",
      "        \"num_layers_unfrozen\": 2,\n",
      "        \"delta_kwargs\": null\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"name\": \"adamw\",\n",
      "        \"kwargs\": {\n",
      "            \"lr\": 0.0001,\n",
      "            \"betas\": [\n",
      "                0.9,\n",
      "                0.95\n",
      "            ],\n",
      "            \"eps\": 1e-08,\n",
      "            \"weight_decay\": 1e-06\n",
      "        }\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "        \"name\": \"cosine_annealing\",\n",
      "        \"kwargs\": {\n",
      "            \"T_max\": 10000,\n",
      "            \"eta_min\": 0.0001\n",
      "        }\n",
      "    },\n",
      "    \"tokenizer\": {\n",
      "        \"tokenizer_path\": \"gpt2\",\n",
      "        \"padding_side\": \"left\",\n",
      "        \"truncation_side\": \"right\"\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"total_steps\": 10,\n",
      "        \"seq_length\": 1024,\n",
      "        \"epochs\": 100,\n",
      "        \"batch_size\": 32,\n",
      "        \"checkpoint_interval\": 10000,\n",
      "        \"eval_interval\": 100,\n",
      "        \"pipeline\": \"PromptPipeline\",\n",
      "        \"trainer\": \"AcceleratePPOTrainer\",\n",
      "        \"trainer_kwargs\": {},\n",
      "        \"project_name\": \"trlx\",\n",
      "        \"entity_name\": null,\n",
      "        \"group_name\": null,\n",
      "        \"checkpoint_dir\": \"ckpts\",\n",
      "        \"rollout_logging_dir\": null,\n",
      "        \"save_best\": true,\n",
      "        \"tracker\": \"tensorboard\",\n",
      "        \"logging_dir\": null,\n",
      "        \"seed\": 1000\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(config.train.trainer)(\n",
    "    config=config,\n",
    "    reward_fn=reward_fn,\n",
    "    **config.train.trainer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbe8ad7-b3d9-433f-b098-090e468053cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trlx.utils import set_seed\n",
    "set_seed(config.train.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264a0431-ebb1-4de8-b41e-ebc0a2c8fa14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithHydraValueHead(\n",
       "  (base_model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (v_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  )\n",
       "  (frozen_head): GPTModelBranch(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-1): 2 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze 10 h-layers, and unfreeze the last 2 h-layers.\n",
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e889f2e-0b24-4bdd-9573-89877755070e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = config.train.batch_size\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5ccb3b-c2a7-4e01-bb93-c3838d6ea22a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prompt_length = config.train.seq_length - config.method.gen_kwargs[\"max_new_tokens\"]\n",
    "max_prompt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1e5c33-e688-4d87-aff6-0a744be20ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM', '\"I Am Curious: Yellow\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = prompts or [trainer.tokenizer.bos_token] * batch_size\n",
    "prompts = prompts[:2]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb8b08f-3462-43d8-ad91-b9ba80cff2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]],\n",
      " 'input_ids': [[40, 26399, 314, 3001], [1, 40, 1703, 44269, 25, 12550, 1]]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(trainer.tokenizer(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6516b9-c0f2-4107-8676-9782b1d22f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'attention_mask': [1, 1, 1, 1], 'input_ids': [40, 26399, 314, 3001]},\n",
      " {'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
      "  'input_ids': [1, 40, 1703, 44269, 25, 12550, 1]}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_pipeline(config.train.pipeline)(prompts, max_prompt_length, trainer.tokenizer)\n",
    "pprint.pprint(pipeline.prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c08850-f520-4410-b56d-4f93ffcb33c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.add_prompt_pipeline(pipeline)\n",
    "ppo_rl_elements = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f5d71d-4470-43d1-bb39-837b20bf8f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1]], device='cuda:0'),\n",
      " 'input_ids': tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
      "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "from trlx.data.accelerate_base_datatypes import PromptBatch\n",
    "# random sampling\n",
    "batch: PromptBatch = next(trainer.prompt_iterator)\n",
    "pprint.pprint(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6925e649-7811-4ab6-b636-bf5a82055cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91bea5bf-f66b-4461-af52-83d8e026fade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[40, 26399, 314, 3001], [1, 40, 1703, 44269, 25, 12550, 1]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.tokenizer(prompts, truncation=True, padding=False, max_length=max_prompt_length, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c032bb-ab22-4091-80f4-e3c224745176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
      "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
      "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
      "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
      "           318,   477,   546,    13,   383,  3437,  2241],\n",
      "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
      "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
      "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
      "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
      "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "samples = trainer.generate(**batch)\n",
    "pprint.pprint(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9afc5496-bccf-4b63-bad0-34e8f66e6be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bcd84a2-5a10-4d2c-8e6b-40a4b72c029f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_tensors = batch.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba67f8dd-54a2-442e-9be3-a485a4c465bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids_expr = torch.Tensor([[1],[2]])\n",
    "input_ids_expr = input_ids_expr.to('cuda', dtype=torch.int)\n",
    "attention_mask_expr = torch.Tensor([[1],[1]])\n",
    "attention_mask_expr = attention_mask_expr.to('cuda', dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72fdab4f-450c-4931-9e89-497da96143cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/sshuser/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   290,   366,   464,  1869,  5338,   509,  3605, 14190, 13111,\n",
       "             1,   389,   262,   691,   734,  7328,   314,  1053,  1775,   326],\n",
       "        [    2,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.generate(input_ids=input_ids_expr, attention_mask=attention_mask_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f59d558-eff0-4411-aa5e-37f6782be51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebad8da8-1437-4699-ba39-84ede5b89a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = trainer.model(input_ids_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33222eb9-acc9-43fa-bdbf-9e1db4a56863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   290,   366,   464,  1869,  5338,   509,  3605, 14190, 13111,\n",
       "             1,   389,   262,   691,   734,  7328,   314,  1053,  1775,   326],\n",
       "        [    2,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.base_model.generate(input_ids=input_ids_expr, attention_mask=attention_mask_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d53a3c6-af03-42a1-860d-e73cfefff310",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,   318,   257,  1049,\n",
       "          3807,    13,   632,   318,   257,  1049,  3807,    13,   632,   318,\n",
       "           257,  1049,  3807,    13,   632,   318,   257,  1049,  3807,    13,\n",
       "           632,   318,   257,  1049,  3807,    13,   632,   318,   257,  1049,\n",
       "          3807,    13,   632,   318,   257,  1049,  3807],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,  3336, 32957,  3963,\n",
       "          3336, 32957,  3963,  3336, 32957,  3963,  3336, 32957,  3963,  3336,\n",
       "         32957,  3963,  3336, 32957,  3963,  3336, 32957,  3963,  3336, 32957,\n",
       "          3963,  3336, 32957,  3963,  3336, 32957,  3963,  3336, 32957,  3963,\n",
       "          3336, 32957,  3963,  3336, 32957,  3963,  3336]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {'max_new_tokens': 40, 'top_k': 1, 'top_p': 1.0, 'do_sample': True, 'eos_token_id': 50256, 'pad_token_id': 50256}\n",
    "trainer.model.base_model.generate(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ad1959-97af-465f-aa90-fba88cfabdbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0946,  0.0982, -0.0275,  ..., -0.1776,  0.1447,  0.0717],\n",
       "        [-0.1265, -0.0656,  0.0332,  ...,  0.1970, -0.1247, -0.0649],\n",
       "        [ 0.0536, -0.0389, -0.0499,  ...,  0.0678, -0.0733,  0.0841],\n",
       "        ...,\n",
       "        [ 0.0514,  0.1575,  0.0029,  ..., -0.3976,  0.0898,  0.0218],\n",
       "        [ 0.0326,  0.1229, -0.0413,  ..., -0.1904,  0.1263, -0.0408],\n",
       "        [-0.0344,  0.0023, -0.0510,  ..., -0.0417,  0.0563,  0.1917]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.base_model.transformer.h[0].mlp.c_fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92296566-184b-4931-8c3f-2045cfdd4218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = samples.device\n",
    "prompt_sizes = torch.tensor([prompt_tensors.shape[1]] * len(prompt_tensors), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bca4ecb3-53c1-43eb-86f1-fd7064e0987c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256, 50256, 50256,    40, 26399,   314,  3001], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e73436-da53-41ae-ac82-5db24d57fd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea436c92-1068-467e-b062-b11d283cabc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded_samples = trainer.accelerator.pad_across_processes(\n",
    "    samples, dim=1, pad_index=trainer.tokenizer.eos_token_id, pad_first=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "456d8591-3030-47f9-b9e4-18181e38fe0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d449109-991d-418f-aa80-2a3a8c9f89c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
       "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
       "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
       "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
       "           318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
       "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
       "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
       "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
       "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc87f326-ceba-4252-81d4-1c81ac894b89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
       "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
       "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
       "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
       "           318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
       "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
       "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
       "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
       "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d2dab1-99d7-450c-bdd6-85918b9bdfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_prompts = trainer.accelerator.pad_across_processes(\n",
    "    prompt_tensors, dim=1, pad_index=trainer.tokenizer.eos_token_id, pad_first=False\n",
    ")\n",
    "padded_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "935f074f-c11f-414a-84c5-492847428df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
       "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
       "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
       "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
       "           318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
       "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
       "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
       "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
       "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered_samples = trainer.accelerator.gather(padded_samples)\n",
    "gathered_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7301bfec-a793-444f-ae1e-037dbb160e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered_prompts = trainer.accelerator.gather(padded_prompts)\n",
    "gathered_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0c485ae-9c7c-42a5-9c62-4f2462cd7413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered_prompt_sizes = trainer.accelerator.gather(prompt_sizes)\n",
    "gathered_prompt_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d393786-dc9d-462c-8451-414b84fa9c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - samples: full sentences.\n",
    "# - prompts: take few words off of movies reviews.\n",
    "# - outputs: outputs generated using prompts\n",
    "all_str_samples, all_str_prompts, all_str_outputs = trainer.decode(\n",
    "    gathered_prompts, gathered_samples, gathered_prompt_sizes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a32ff6ef-80fc-4496-8c9c-d07d194223a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"I Am Curious: Yellow\" although neither of the other films was directed as similar as Ye\\'en\\'s koja. So, Jamie Lynn is the only one who really struggles to understand what this is all about. The director himself',\n",
       " 'I rented I AM a second run and was surprised to find Andreas Spitz really appealing to some parts of the build an unexpected life performance in real life. The saves in this movie were stupid and lacked real life ability.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_str_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ebf529-41dc-49c3-a63e-70768e09ff11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"I Am Curious: Yellow\"', 'I rented I AM']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_str_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63a15c6d-3a8a-4557-a4f7-373a0c145081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" although neither of the other films was directed as similar as Ye'en's koja. So, Jamie Lynn is the only one who really struggles to understand what this is all about. The director himself\",\n",
       " ' a second run and was surprised to find Andreas Spitz really appealing to some parts of the build an unexpected life performance in real life. The saves in this movie were stupid and lacked real life ability.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_str_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c38a7936-360f-42eb-80fb-db223ff1e3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_scores = torch.tensor(\n",
    "    trainer.reward_fn(\n",
    "        samples=all_str_samples,\n",
    "        prompts=all_str_prompts,\n",
    "        outputs=all_str_outputs,\n",
    "    ),\n",
    "    dtype=torch.float,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4898436-3086-4faf-a4fc-ac598854adf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4048, 0.0483], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72cd3d7c-358c-4164-83ae-1402d65136a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.4048, 0.0483], device='cuda:0')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = list(all_scores.reshape(trainer.accelerator.num_processes, -1).unbind())\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0e2f863-b1ea-492c-b06f-98c43aaa3469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_422613/162157691.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scores = torch.tensor(all_scores[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4048, 0.0483], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.tensor(all_scores[0])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fb15bb7-c76f-4da0-854c-31f6d9c1d4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_samples, str_prompts, str_outputs = trainer.decode(prompt_tensors, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "537df1a4-3944-4feb-89b1-16d272bfe97f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"I Am Curious: Yellow\" although neither of the other films was directed as similar as Ye\\'en\\'s koja. So, Jamie Lynn is the only one who really struggles to understand what this is all about. The director himself',\n",
       " 'I rented I AM a second run and was surprised to find Andreas Spitz really appealing to some parts of the build an unexpected life performance in real life. The saves in this movie were stupid and lacked real life ability.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17dd5fac-0fa6-4514-a5c5-00d74b377cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"I Am Curious: Yellow\" although neither of the other films was directed as similar as Ye\\'en\\'s koja. So, Jamie Lynn is the only one who really struggles to understand what this is all about. The director himself',\n",
       " 'I rented I AM a second run and was surprised to find Andreas Spitz really appealing to some parts of the build an unexpected life performance in real life. The saves in this movie were stupid and lacked real life ability.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_str_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45de6a38-924c-485c-80cb-0e5660dd76d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3584,  6159,   286,   262,   584,  7328,   373,  7924,   355,  2092,\n",
       "           355, 11609,     6,   268,   338, 41727,  6592,    13,  1406,    11,\n",
       "         17826, 24868,   318,   262,   691,   530,   508,  1107, 12766,   284,\n",
       "          1833,   644,   428,   318,   477,   546,    13,   383,  3437,  2241]),\n",
       " tensor([  257,  1218,  1057,   290,   373,  6655,   284,  1064, 33728,  1338,\n",
       "          4224,  1107, 16403,   284,   617,  3354,   286,   262,  1382,   281,\n",
       "         10059,  1204,  2854,   287,  1103,  1204,    13,   383, 16031,   287,\n",
       "           428,  3807,   547,  8531,   290, 19989,  1103,  1204,  2694,    13])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = trainer.tokenizer(str_outputs).input_ids\n",
    "outputs = list(map(torch.LongTensor, outputs))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b64fe2b8-45ea-48b8-83c8-1a8119daae6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsize = max(map(len, outputs))\n",
    "maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ad64271-c7da-4f30-be2b-75d0a1a57043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3584,  6159,   286,   262,   584,  7328,   373,  7924,   355,  2092,\n",
       "           355, 11609,     6,   268,   338, 41727,  6592,    13,  1406,    11,\n",
       "         17826, 24868,   318,   262,   691,   530,   508,  1107, 12766,   284,\n",
       "          1833,   644,   428,   318,   477,   546,    13,   383,  3437,  2241]),\n",
       " tensor([  257,  1218,  1057,   290,   373,  6655,   284,  1064, 33728,  1338,\n",
       "          4224,  1107, 16403,   284,   617,  3354,   286,   262,  1382,   281,\n",
       "         10059,  1204,  2854,   287,  1103,  1204,    13,   383, 16031,   287,\n",
       "           428,  3807,   547,  8531,   290, 19989,  1103,  1204,  2694,    13])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "outputs = [\n",
    "    F.pad(\n",
    "        output,\n",
    "        (0, maxsize - len(output)),\n",
    "        value=trainer.tokenizer.pad_token_id,\n",
    "    )\n",
    "    for output in outputs\n",
    "]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd1a3c1b-94b0-4dac-aca5-b13e9e8c3e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3584,  6159,   286,   262,   584,  7328,   373,  7924,   355,  2092,\n",
       "           355, 11609,     6,   268,   338, 41727,  6592,    13,  1406,    11,\n",
       "         17826, 24868,   318,   262,   691,   530,   508,  1107, 12766,   284,\n",
       "          1833,   644,   428,   318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [  257,  1218,  1057,   290,   373,  6655,   284,  1064, 33728,  1338,\n",
       "          4224,  1107, 16403,   284,   617,  3354,   286,   262,  1382,   281,\n",
       "         10059,  1204,  2854,   287,  1103,  1204,    13,   383, 16031,   287,\n",
       "           428,  3807,   547,  8531,   290, 19989,  1103,  1204,  2694,    13]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_outputs = torch.vstack(outputs).to(device)\n",
    "sample_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26a0d261-648a-41ac-ac95-c5916b661c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.ref_mean, trainer.ref_std = scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e36ca34-c41e-4f70-a81e-0db350e522b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_scores_mean, all_scores_std = trainer.running_moments.update(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6b48786-9b9a-48a1-bfc7-b7ea4f778e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2266, device='cuda:0'),\n",
       " tensor(0.2266, device='cuda:0'),\n",
       " tensor(0.2521, device='cuda:0'),\n",
       " tensor(0.2521, device='cuda:0'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.ref_mean, all_scores_mean, trainer.ref_std, all_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0dc8ebe-0434-4c0e-96fe-10a0b03540ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_reward = trainer.config.method.cliprange_reward\n",
    "clip_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ca42c49-11a6-4943-9f5d-b2a8e2032c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4048, 0.0483], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.clip(scores, -clip_reward, clip_reward)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8aa18615-a020-4289-9585-0e8acad7b57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
       "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
       "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
       "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
       "           318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
       "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
       "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
       "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
       "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = torch.cat((prompt_tensors.to(device), sample_outputs), dim=1)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c4777b1-9ec2-42b0-a7e1-0c538329fee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    40,  1703, 44269,    25, 12550,     1,  3584,  6159,   286,\n",
       "           262,   584,  7328,   373,  7924,   355,  2092,   355, 11609,     6,\n",
       "           268,   338, 41727,  6592,    13,  1406,    11, 17826, 24868,   318,\n",
       "           262,   691,   530,   508,  1107, 12766,   284,  1833,   644,   428,\n",
       "           318,   477,   546,    13,   383,  3437,  2241],\n",
       "        [50256, 50256, 50256,    40, 26399,   314,  3001,   257,  1218,  1057,\n",
       "           290,   373,  6655,   284,  1064, 33728,  1338,  4224,  1107, 16403,\n",
       "           284,   617,  3354,   286,   262,  1382,   281, 10059,  1204,  2854,\n",
       "           287,  1103,  1204,    13,   383, 16031,   287,   428,  3807,   547,\n",
       "          8531,   290, 19989,  1103,  1204,  2694,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "989e14e9-716a-4aab-9a03-21f1df7bdaba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = all_tokens.not_equal(trainer.tokenizer.pad_token_id).long().to(device)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9bbabbbf-ad6c-4cbc-ad42-d0590ab7ff03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# values : Uses base_model's output, and goes through v_head(2 lyrs) one more time.\n",
    "logits, *_, values = trainer.model(\n",
    "    all_tokens,\n",
    "    attention_mask=attention_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16db9b84-4cad-4fef-9c50-b0203c84bc43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1144, -1.6477, -0.7635, -0.7435, -0.4699, -0.5392, -0.7150, -1.2081,\n",
       "         -1.1719, -0.7929, -1.2340, -1.2667, -1.4014, -1.4717, -0.7298, -0.7724,\n",
       "         -0.4831, -0.8247, -0.5923, -0.5602, -0.3411, -0.7314, -0.4289, -0.5899,\n",
       "         -0.2241, -0.8277, -1.2634,  0.2456, -0.2927, -0.9984, -0.8142, -1.0425,\n",
       "         -1.0788, -1.0885, -1.2277, -0.7496, -0.9655, -0.7919, -1.1532, -1.0226,\n",
       "         -0.8372, -0.6618, -0.3051, -0.2710, -0.8394, -0.8853, -0.8451],\n",
       "        [-0.1301, -0.1811, -0.1861, -0.4533, -0.9991, -0.7957,  0.2317, -0.1800,\n",
       "         -0.4699, -0.7473, -0.7988, -0.6913, -0.4419, -0.4495, -0.2182, -0.1093,\n",
       "         -0.1637, -0.1946,  0.0114, -0.0950, -0.1235, -0.4455, -0.3586, -0.3516,\n",
       "         -0.5608, -0.2130, -0.1212, -0.4105, -0.3970, -0.2640, -0.2569, -0.2457,\n",
       "         -0.1830,  0.0729, -0.1008, -0.3603, -0.2137,  0.0231,  0.1038, -0.3651,\n",
       "         -0.2889, -0.2839, -0.1293, -0.2133, -0.1907, -0.3309, -0.0599]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9eb246a1-2c48-406e-9a4e-b0ab4d424b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47, 50257])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48fb3037-809c-4ca7-833f-cc3fbc874440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dc9ac5a-97e1-441f-a17b-75ba27002adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44d3906d-8e92-4d62-89db-6835bbe7645d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39139b0e-0b35-4825-bc04-ddc52defebb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x GPT2Block(\n",
       "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): GPT2Attention(\n",
       "      (c_attn): Conv1D()\n",
       "      (c_proj): Conv1D()\n",
       "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): GPT2MLP(\n",
       "      (c_fc): Conv1D()\n",
       "      (c_proj): Conv1D()\n",
       "      (act): NewGELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trlx.utils.modeling as modeling_utils\n",
    "hidden_layers = modeling_utils.hf_get_decoder_blocks(trainer.model.base_model)\n",
    "hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8179045c-00d8-4b69-80b1-99c128ae0b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47, 50257])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_logits = trainer.model.forward_hydra(\n",
    "    all_tokens,\n",
    "    attention_mask=attention_mask,\n",
    "    return_dict=True,\n",
    ").logits\n",
    "ref_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b5e749f-7913-4440-beff-bf88932eee59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithHydraValueHead(\n",
       "  (base_model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (v_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  )\n",
       "  (frozen_head): GPTModelBranch(\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-1): 2 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4edd3df2-c918-4001-abfa-7c8d72c60406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits, *_, values = trainer.model.forward(\n",
    "    all_tokens,\n",
    "    attention_mask=attention_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4a228a7-146d-4b25-ab38-92c590783cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1144, -1.6477, -0.7635, -0.7435, -0.4699, -0.5392, -0.7150, -1.2081,\n",
       "         -1.1719, -0.7929, -1.2340, -1.2667, -1.4014, -1.4717, -0.7298, -0.7724,\n",
       "         -0.4831, -0.8247, -0.5923, -0.5602, -0.3411, -0.7314, -0.4289, -0.5899,\n",
       "         -0.2241, -0.8277, -1.2634,  0.2456, -0.2927, -0.9984, -0.8142, -1.0425,\n",
       "         -1.0788, -1.0885, -1.2277, -0.7496, -0.9655, -0.7919, -1.1532, -1.0226,\n",
       "         -0.8372, -0.6618, -0.3051, -0.2710, -0.8394, -0.8853, -0.8451],\n",
       "        [-0.1301, -0.1811, -0.1861, -0.4533, -0.9991, -0.7957,  0.2317, -0.1800,\n",
       "         -0.4699, -0.7473, -0.7988, -0.6913, -0.4419, -0.4495, -0.2182, -0.1093,\n",
       "         -0.1637, -0.1946,  0.0114, -0.0950, -0.1235, -0.4455, -0.3586, -0.3516,\n",
       "         -0.5608, -0.2130, -0.1212, -0.4105, -0.3970, -0.2640, -0.2569, -0.2457,\n",
       "         -0.1830,  0.0729, -0.1008, -0.3603, -0.2137,  0.0231,  0.1038, -0.3651,\n",
       "         -0.2889, -0.2839, -0.1293, -0.2133, -0.1907, -0.3309, -0.0599]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c37347a0-8bf4-448b-9e68-17daa59d77e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47, 50257])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3e6a059-f17d-4f3a-882a-7a974c391a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 46])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trlx.utils.modeling import RunningMoments, logprobs_of_labels\n",
    "logprobs = logprobs_of_labels(logits[:, :-1, :], all_tokens[:, 1:])\n",
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59f48b6a-d59e-42af-8409-1a4c31579019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 46])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original value\n",
    "ref_logprobs = logprobs_of_labels(ref_logits[:, :-1, :], all_tokens[:, 1:])\n",
    "ref_logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5484f213-9dfa-44f6-8b11-867fc723fa75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples: int = samples.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fb19c49-a8aa-4c9d-a442-391890451474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the KL divergence between the model and reference model\n",
    "start = prompt_tensors.shape[1] - 1\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8090bc3d-fc0f-4f40-b35c-6a3c84fbdb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ratio = (logprobs - ref_logprobs) * attention_mask[:, :-1]\n",
    "log_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b6aeb34-e4e5-42cc-a0bd-d21d1687374a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.mean_kl = (log_ratio.exp() - 1 - log_ratio).mean().to(device)\n",
    "trainer.mean_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2774c96-0f01-4870-9087-a34f746ec292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends = start + attention_mask[:, start:].sum(1)\n",
    "ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7e6e996-b20a-4046-92f4-49f57f7bb406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 47])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8072e1a3-bb48-4718-a44b-89e42431b15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.7150, -1.2081, -1.1719, -0.7929, -1.2340, -1.2667, -1.4014, -1.4717,\n",
       "         -0.7298, -0.7724, -0.4831, -0.8247, -0.5923, -0.5602, -0.3411, -0.7314,\n",
       "         -0.4289, -0.5899, -0.2241, -0.8277, -1.2634,  0.2456, -0.2927, -0.9984,\n",
       "         -0.8142, -1.0425, -1.0788, -1.0885, -1.2277, -0.7496, -0.9655, -0.7919,\n",
       "         -1.1532, -1.0226, -0.8372, -0.6618, -0.3051, -0.2710, -0.8394, -0.8853,\n",
       "         -0.8451], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([ 0.2317, -0.1800, -0.4699, -0.7473, -0.7988, -0.6913, -0.4419, -0.4495,\n",
       "         -0.2182, -0.1093, -0.1637, -0.1946,  0.0114, -0.0950, -0.1235, -0.4455,\n",
       "         -0.3586, -0.3516, -0.5608, -0.2130, -0.1212, -0.4105, -0.3970, -0.2640,\n",
       "         -0.2569, -0.2457, -0.1830,  0.0729, -0.1008, -0.3603, -0.2137,  0.0231,\n",
       "          0.1038, -0.3651, -0.2889, -0.2839, -0.1293, -0.2133, -0.1907, -0.3309,\n",
       "         -0.0599], device='cuda:0', grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values = [values[ix, start: ends[ix]] for ix in range(n_samples)]\n",
    "all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e833ed5-1df5-4c78-8552-767f8b719557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-8.0056e+00, -7.1409e+00, -1.8413e+00, -1.4369e+00, -2.7020e+00,\n",
       "         -1.2303e+00, -3.0204e+00, -2.9217e+00, -5.7553e+00, -7.2738e+00,\n",
       "         -1.4152e+00, -9.8927e+00, -5.8801e+00, -5.2949e+00, -1.7356e+00,\n",
       "         -1.4803e+01, -5.6885e+00, -1.8524e+00, -4.5328e+00, -1.5505e+00,\n",
       "         -1.1950e+01, -4.3547e+00, -1.8808e+00, -2.2701e+00, -2.0085e+00,\n",
       "         -9.3521e-01, -1.0281e+00, -3.1574e+00, -6.5488e+00, -1.0721e+00,\n",
       "         -3.2327e+00, -2.0036e+00, -3.6637e+00, -2.1087e+00, -7.9226e-01,\n",
       "         -1.2594e-02, -7.9068e-01, -2.4174e+00, -4.6679e+00, -4.7881e+00],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " tensor([-12.2430,  -7.2060,  -9.7343,  -5.3320,  -8.3455, -10.2839,  -5.4186,\n",
       "          -4.7302, -13.8492, -16.6296,  -6.6775, -13.8959, -15.1789,  -5.2657,\n",
       "          -8.3728,  -3.2701,  -4.7287,  -5.7416, -14.0443,  -6.4452,  -8.1692,\n",
       "          -9.0305, -11.1253,  -5.2776,  -8.1605,  -0.9804,  -4.5875,  -3.3391,\n",
       "         -12.2452,  -6.0990,  -6.0489,  -6.0177,  -1.9688, -11.4443,  -3.0154,\n",
       "          -8.2383,  -6.6995,  -0.7526,  -8.6550,  -0.4860], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logprobs = [logprobs[ix, start: ends[ix]] for ix in range(n_samples)]\n",
    "all_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37195236-ecf2-4866-8c05-0a8d7c1f99f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_penalty = trainer.kl_ctl.value * -log_ratio.cpu()\n",
    "kl_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "051ef51e-b6e5-473c-866f-7af9a35a61b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "        grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_penalty = [xs[start: ends[ix]] for ix, xs in enumerate(kl_penalty)]\n",
    "kl_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18fa55e5-6953-4fcd-8176-362c9b617fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = kl_penalty[0]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0999fa71-ac17-461a-8e4c-115772870c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.kl_ctl.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca30fb6d-b644-4617-9e9f-d785f8b800fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "        grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04b10ce5-5c64-419c-af1a-d8a0323f75f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6c632cb-0042-4a1d-93ad-9ce2f3b06017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4048)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "366d3e30-7cc7-48b1-be47-8aea45c22db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rewards[-1] += scores[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aebd3143-62a0-4480-b770-6984901723f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40]), torch.Size([46]), torch.Size([47]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.shape, logprobs[0].shape, values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35fc0ff7-5435-4748-8b6a-c080c0b785db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_length = rewards.shape[0]\n",
    "response_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05106c36-9114-4821-81e5-3e2e601fe086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 47]), torch.Size([40]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape, rewards.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
